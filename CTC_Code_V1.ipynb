{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title CTC (arXiv:2109.02473) — Colab One-Cell Runner (GitHub ZIP fix)\n",
        "#@markdown This version downloads the **entire CTC repo zip** and reads validation data from its folders.\n",
        "#@markdown <br>Keep **Tiny demo** on for a quick recording; switch off + enable **Zenodo** for fuller replication later.\n",
        "\n",
        "# ==== OPTIONS (Colab form) ====\n",
        "TINY_DEMO: bool = True  # @param {type:\"boolean\"}\n",
        "TINY_N: int = 100000     # @param {type:\"integer\"}\n",
        "TRAIN_MODELS: bool = True  # @param {type:\"boolean\"}\n",
        "RUN_PREDICT: bool = True   # @param {type:\"boolean\"}\n",
        "USE_DNN: bool = True       # @param {type:\"boolean\"}\n",
        "EPOCHS: int = 3            # @param {type:\"integer\"}\n",
        "BATCH_SIZE: int = 512      # @param {type:\"integer\"}\n",
        "DOWNLOAD_ZENODO: bool = False  # @param {type:\"boolean\"}\n",
        "WORKDIR: str = \"work_colab\"    # @param {type:\"string\"}\n",
        "\n",
        "# ==== Minimal deps (TensorFlow is preinstalled on Colab) ====\n",
        "import sys, subprocess, importlib.util\n",
        "def pip_install(pkgs):\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + pkgs, check=True)\n",
        "\n",
        "need = []\n",
        "for pkg in [\"scikit-learn\", \"joblib\", \"tqdm\", \"beautifulsoup4\", \"lxml\", \"html5lib\", \"requests\", \"scipy\", \"pandas\", \"numpy\"]:\n",
        "    if importlib.util.find_spec(pkg) is None:\n",
        "        need.append(pkg)\n",
        "if need:\n",
        "    pip_install(need)\n",
        "\n",
        "# ==== Imports ====\n",
        "import os, re, tarfile, zipfile, json, io, shutil, time, random\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import joblib\n",
        "\n",
        "# TensorFlow (use CPU if no GPU)\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import layers\n",
        "    TF_OK = True\n",
        "except Exception as e:\n",
        "    print(\"TensorFlow not available; continuing without DNN. Error:\", e)\n",
        "    TF_OK = False\n",
        "    USE_DNN = False\n",
        "\n",
        "# ==== Constants (authors' repo + Zenodo) ====\n",
        "# Repo with validation folders & dictionary:\n",
        "CTC_REPO_ZIP = \"https://codeload.github.com/epelofske-student/CTC/zip/refs/heads/main\"  # full repo as zip\n",
        "# Files we will read from the unzipped repo:\n",
        "DICT_REPO_PATH = \"English_word_dictionary.txt\" # Corrected path\n",
        "VAL_DIR_CYB = \"validation_data_cybersecurity\" # Corrected path\n",
        "VAL_DIR_NON = \"validation_data_non_cybersecurity\" # Corrected path\n",
        "# Big training set (optional):\n",
        "ZENODO_URL = \"https://zenodo.org/records/10655913/files/CTC_training_data.tar.gz?download=1\"  # ~3.1 GB\n",
        "\n",
        "# ==== FS helpers ====\n",
        "W = Path(WORKDIR)\n",
        "DATA = W / \"data\"\n",
        "MODELS = W / \"models\"\n",
        "for p in (W, DATA, MODELS):\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def stream_download(url: str, out_path: Path, desc: str = None):\n",
        "    if out_path.exists() and out_path.stat().st_size > 0:\n",
        "        return\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        total = int(r.headers.get(\"content-length\", 0))\n",
        "        with open(out_path, \"wb\") as f, tqdm(total=total, unit=\"B\", unit_scale=True, desc=desc or out_path.name) as pbar:\n",
        "            for chunk in r.iter_content(chunk_size=1024 * 1024):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "                    pbar.update(len(chunk))\n",
        "\n",
        "def extract_tar_gz(tar_path: Path, out_dir: Path):\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
        "        tar.extractall(path=out_dir)\n",
        "\n",
        "def extract_zip(zip_path: Path, out_dir: Path):\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "        z.extractall(out_dir)\n",
        "\n",
        "# ==== Cleaning ====\n",
        "CLEAN_HTML_RE = re.compile(r\"<[^>]+>\")\n",
        "URL_RE = re.compile(r\"http[s]?://\\S+|www\\.\\S+\")\n",
        "CODE_RE = re.compile(r\"`{1,3}.*?`{1,3}\", re.DOTALL)\n",
        "NON_ASCII_RE = re.compile(r\"[^\\x00-\\x7F]+\")\n",
        "WHITESPACE_RE = re.compile(r\"\\s+\")\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = URL_RE.sub(\" \", text)\n",
        "    text = CODE_RE.sub(\" \", text)\n",
        "    text = CLEAN_HTML_RE.sub(\" \", text)\n",
        "    text = NON_ASCII_RE.sub(\" \", text)\n",
        "    text = WHITESPACE_RE.sub(\" \", text).strip()\n",
        "    return text\n",
        "\n",
        "def read_text_dir(dir_path: Path, max_files=None) -> List[str]:\n",
        "    files = sorted([p for p in dir_path.rglob(\"*\") if p.is_file()])\n",
        "    if max_files is not None:\n",
        "        files = files[:max_files]\n",
        "    texts = []\n",
        "    for p in files:\n",
        "        try:\n",
        "            txt = p.read_text(\"utf-8\", errors=\"ignore\")\n",
        "            texts.append(clean_text(txt))\n",
        "        except Exception:\n",
        "            continue\n",
        "    return texts\n",
        "\n",
        "def load_training_json(json_path: Path, tiny=False, tiny_n=50000) -> Tuple[List[str], List[int]]:\n",
        "    data = json.loads(json_path.read_text(\"utf-8\"))\n",
        "    if tiny:\n",
        "        data = random.sample(data, min(tiny_n, len(data)))\n",
        "    X = [clean_text(d.get(\"text\",\"\")) for d in data]\n",
        "    y = [int(d.get(\"label\", 0)) for d in data]\n",
        "    return X, y\n",
        "\n",
        "def make_vectorizer_from_dictionary(dict_path: Path) -> TfidfVectorizer:\n",
        "    # Read vocabulary, remove duplicates, and filter out empty lines\n",
        "    vocab_lines = dict_path.read_text(\"utf-8\").splitlines()\n",
        "    vocab = sorted(list(set(w.strip() for w in vocab_lines if w.strip())))\n",
        "\n",
        "    vec = TfidfVectorizer(\n",
        "        vocabulary=vocab,\n",
        "        lowercase=True,\n",
        "        dtype=np.float32,\n",
        "        token_pattern=r\"(?u)\\b\\w+\\b\",\n",
        "        max_df=1.0,\n",
        "        min_df=1\n",
        "    )\n",
        "    return vec\n",
        "\n",
        "def build_models(random_state=42):\n",
        "    return {\n",
        "        \"DecisionTree\": DecisionTreeClassifier(max_depth=100, random_state=random_state),\n",
        "        \"RandomForest\": RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=random_state),\n",
        "        \"Logistic\":     LogisticRegression(max_iter=300, n_jobs=-1, solver=\"saga\", penalty=\"l2\"),\n",
        "        \"LinearSVC\":    LinearSVC(),\n",
        "        \"MLP\":          MLPClassifier(hidden_layer_sizes=(256,), activation=\"relu\", max_iter=15, random_state=random_state)\n",
        "    }\n",
        "\n",
        "def build_dnn(input_dim: int):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(256, activation=\"relu\"),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(2, activation=\"softmax\"),\n",
        "    ])\n",
        "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def majority_vote(preds_bin: List[np.ndarray]) -> np.ndarray:\n",
        "    stacked = np.vstack(preds_bin)   # (M, N)\n",
        "    votes = stacked.sum(axis=0)\n",
        "    return (votes >= (stacked.shape[0] / 2.0)).astype(int)\n",
        "\n",
        "# ==== Get the authors' repo as a ZIP and set paths ====\n",
        "repo_zip = DATA / \"CTC-main.zip\"\n",
        "repo_root = DATA / \"CTC-main\"\n",
        "if not repo_root.exists():\n",
        "    print(\"Downloading CTC repo (validation folders + dictionary) ...\")\n",
        "    stream_download(CTC_REPO_ZIP, repo_zip, desc=\"CTC-main.zip\")\n",
        "    extract_zip(repo_zip, DATA)\n",
        "\n",
        "# Dictionary path from repo\n",
        "dict_path = repo_root / DICT_REPO_PATH\n",
        "if not dict_path.exists():\n",
        "    raise FileNotFoundError(f\"Dictionary not found inside repo ZIP at {repo_root / DICT_REPO_PATH}\")\n",
        "\n",
        "# Validation dirs from repo\n",
        "val_dir_cyb = repo_root / VAL_DIR_CYB\n",
        "val_dir_non = repo_root / VAL_DIR_NON\n",
        "for p in (val_dir_cyb, val_dir_non):\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"Validation folder missing: {p}\")\n",
        "\n",
        "# ==== Optional: download big Zenodo training set ====\n",
        "train_json = DATA / \"CTC_training_data.json\"\n",
        "train_tgz  = DATA / \"CTC_training_data.tar.gz\"\n",
        "if DOWNLOAD_ZENODO and not train_json.exists():\n",
        "    print(\"Downloading Zenodo training set (~3.1 GB).\")\n",
        "    stream_download(ZENODO_URL, train_tgz, desc=\"CTC_training_data.tar.gz\")\n",
        "    with tarfile.open(train_tgz, \"r:gz\") as tar:\n",
        "        members = [m for m in tar.getmembers() if m.name.endswith(\".json\")]\n",
        "        if members:\n",
        "            f = tar.extractfile(members[0])\n",
        "            train_json.write_bytes(f.read())\n",
        "\n",
        "# ==== Build TF-IDF vectorizer with authors' dictionary ====\n",
        "vec = make_vectorizer_from_dictionary(dict_path)\n",
        "\n",
        "# ==== Prepare training data ====\n",
        "if train_json.exists():\n",
        "    X_text_all, y_all = load_training_json(train_json, tiny=TINY_DEMO, tiny_n=TINY_N)\n",
        "else:\n",
        "    # Tiny fallback: sample from validation sets just to get you running\n",
        "    print(\"Using tiny fallback sample from validation folders (demo).\")\n",
        "    X_c = read_text_dir(val_dir_cyb, max_files=min(5000, TINY_N))\n",
        "    X_n = read_text_dir(val_dir_non, max_files=min(5000, TINY_N))\n",
        "    y_all = [1]*len(X_c) + [0]*len(X_n)\n",
        "    X_text_all = X_c + X_n\n",
        "\n",
        "# Split 70% train, 30% temp\n",
        "X_train_text, X_temp_text, y_train, y_temp = train_test_split(\n",
        "    X_text_all, y_all, test_size=0.3, random_state=42, stratify=y_all\n",
        ")\n",
        "\n",
        "# Split 30% temp into 20% test and 10% validation (relative to original data size)\n",
        "# 20% of original is (20/30) of temp, 10% of original is (10/30) of temp = 1/3\n",
        "X_test_text, X_val_text, y_test, y_val = train_test_split(\n",
        "    X_temp_text, y_temp, test_size=1/3, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# Vectorize\n",
        "X_train = vec.fit_transform(X_train_text)\n",
        "X_val   = vec.transform(X_val_text)\n",
        "X_test  = vec.transform(X_test_text) # Vectorize the test set as well\n",
        "joblib.dump(vec, MODELS / \"tfidf_vectorizer.joblib\")\n",
        "\n",
        "# ==== Train ====\n",
        "if TRAIN_MODELS:\n",
        "    classes = np.array([0,1])\n",
        "    cw_vals = compute_class_weight(\"balanced\", classes=classes, y=np.array(y_train))\n",
        "    class_weights = {int(i): float(w) for i, w in zip(classes, cw_vals)}\n",
        "\n",
        "    # scikit models\n",
        "    sk_models = build_models()\n",
        "    for name, model in sk_models.items():\n",
        "        print(f\"\\nTraining {name} ...\")\n",
        "        try:\n",
        "            if hasattr(model, \"class_weight\"):\n",
        "                model.set_params(class_weight=\"balanced\")\n",
        "        except Exception:\n",
        "            pass\n",
        "        # Train on X_train, evaluate on X_val\n",
        "        model.fit(X_train, y_train)\n",
        "        preds_val = model.predict(X_val)\n",
        "        acc_val = accuracy_score(y_val, preds_val)\n",
        "        print(f\"{name} val acc: {acc_val:.4f}\")\n",
        "        joblib.dump(model, MODELS / f\"{name}.joblib\")\n",
        "\n",
        "    # DNN\n",
        "    if USE_DNN and TF_OK:\n",
        "        print(\"\\nTraining DNN ...\")\n",
        "        dnn = build_dnn(X_train.shape[1])\n",
        "        # Train on X_train, evaluate on X_val during training\n",
        "        dnn.fit(\n",
        "            X_train.toarray(), np.array(y_train),\n",
        "            validation_data=(X_val.toarray(), np.array(y_val)),\n",
        "            epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=2\n",
        "        )\n",
        "        dnn.save(MODELS / \"DNN.keras\")\n",
        "\n",
        "# ==== Evaluate on the new Test set (20% split) ====\n",
        "if TRAIN_MODELS or RUN_PREDICT: # Evaluate on test if models were trained or prediction is requested\n",
        "    print(\"\\n=== Evaluating models on the new Test set (20% split) ===\")\n",
        "    vec_loaded, models_loaded, dnn_loaded = load_models() # Ensure models are loaded\n",
        "    X_test_vec = vec_loaded.transform(X_test_text) # Vectorize test text using the loaded vectorizer\n",
        "\n",
        "    # Evaluate individual models on test set\n",
        "    for name, model in models_loaded.items():\n",
        "        try:\n",
        "            preds_test = model.predict(X_test_vec)\n",
        "        except Exception:\n",
        "            preds_test = model.decision_function(X_test_vec)\n",
        "            preds_test = (preds_test > 0).astype(int)\n",
        "        acc_test = accuracy_score(y_test, preds_test)\n",
        "        print(f\"{name} test acc: {acc_test:.4f}\")\n",
        "\n",
        "    # Evaluate DNN on test set\n",
        "    if dnn_loaded is not None:\n",
        "        loss, acc_test_dnn = dnn_loaded.evaluate(X_test_vec.toarray(), np.array(y_test), verbose=0)\n",
        "        print(f\"DNN test acc: {acc_test_dnn:.4f}\")\n",
        "\n",
        "    # Evaluate Ensemble (Majority Vote) on test set\n",
        "    preds_bin_test = []\n",
        "    for name, m in models_loaded.items():\n",
        "        try:\n",
        "            preds = m.predict(X_test_vec)\n",
        "        except Exception:\n",
        "             preds = m.decision_function(X_test_vec)\n",
        "             preds = (preds > 0).astype(int)\n",
        "        preds_bin_test.append(preds.astype(int))\n",
        "\n",
        "    if dnn_loaded is not None:\n",
        "         p = dnn_loaded.predict(X_test_vec.toarray(), verbose=0)\n",
        "         preds_bin_test.append(np.argmax(p, axis=1).astype(int))\n",
        "\n",
        "    if preds_bin_test: # Ensure there's at least one model prediction\n",
        "        maj_test = majority_vote(preds_bin_test)\n",
        "        acc_maj_test = accuracy_score(y_test, maj_test)\n",
        "        report_maj_test = classification_report(y_test, maj_test, target_names=[\"non-cybersecurity\", \"cybersecurity\"], output_dict=True)\n",
        "        print(f\"\\nEnsemble (Majority Vote) test acc: {acc_maj_test:.4f}\")\n",
        "        print(\"Ensemble Test Classification Report:\")\n",
        "        print(json.dumps(report_maj_test, indent=2))\n",
        "    else:\n",
        "        print(\"\\nNo models available to evaluate ensemble on test set.\")\n",
        "\n",
        "\n",
        "# ==== Predict on authors’ validation sets (original step) ====\n",
        "# This uses the separate validation folders from the repo, not the 10% split\n",
        "if RUN_PREDICT:\n",
        "    print(\"\\n=== Evaluating ensemble (CTC majority vote) on authors' original validation folders ===\")\n",
        "    # Ensure models are loaded - already done above if TRAIN_MODELS or RUN_PREDICT was True\n",
        "    # vec_loaded, models_loaded, dnn_loaded = load_models() # Uncomment if only RUN_PREDICT is True\n",
        "\n",
        "    cs_acc, cs_fp, cs_fn, n1 = infer_on_dir(vec_loaded, models_loaded, dnn_loaded, val_dir_cyb, 1)\n",
        "    nc_acc, nc_fp, nc_fn, n0 = infer_on_dir(vec_loaded, models_loaded, dnn_loaded, val_dir_non, 0)\n",
        "    print(f\"Authors' Cybersecurity Val:      acc={cs_acc:.4f}, FP={cs_fp:.4f}, FN={cs_fn:.4f}, N={n1}\")\n",
        "    print(f\"Authors' Non-cybersecurity Val:  acc={nc_acc:.4f}, FP={nc_fp:.4f}, FN={nc_fn:.4f}, N={n0}\")\n",
        "    print(\"\\nDone ✅ — ready for your screen recording.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad5Kw7Dzcyec",
        "outputId": "885fd8da-1183-4e8b-e1c9-0ee8f441e4ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using tiny fallback sample from validation folders (demo).\n",
            "\n",
            "Training DecisionTree ...\n",
            "DecisionTree val acc: 1.0000\n",
            "\n",
            "Training RandomForest ...\n",
            "RandomForest val acc: 1.0000\n",
            "\n",
            "Training Logistic ...\n",
            "Logistic val acc: 0.5000\n",
            "\n",
            "Training LinearSVC ...\n",
            "LinearSVC val acc: 0.5000\n",
            "\n",
            "Training MLP ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP val acc: 0.5000\n",
            "\n",
            "Training DNN ...\n",
            "Epoch 1/3\n",
            "1/1 - 1s - 1s/step - accuracy: 0.3636 - loss: 0.6940 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
            "Epoch 2/3\n",
            "1/1 - 0s - 187ms/step - accuracy: 0.6364 - loss: 0.6854 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
            "Epoch 3/3\n",
            "1/1 - 0s - 143ms/step - accuracy: 0.6364 - loss: 0.6809 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "\n",
            "=== Evaluating models on the new Test set (20% split) ===\n",
            "DecisionTree test acc: 0.6667\n",
            "RandomForest test acc: 0.6667\n",
            "Logistic test acc: 0.6667\n",
            "LinearSVC test acc: 0.6667\n",
            "MLP test acc: 0.6667\n",
            "DNN test acc: 0.6667\n",
            "\n",
            "Ensemble (Majority Vote) test acc: 0.6667\n",
            "Ensemble Test Classification Report:\n",
            "{\n",
            "  \"non-cybersecurity\": {\n",
            "    \"precision\": 0.6666666666666666,\n",
            "    \"recall\": 1.0,\n",
            "    \"f1-score\": 0.8,\n",
            "    \"support\": 2.0\n",
            "  },\n",
            "  \"cybersecurity\": {\n",
            "    \"precision\": 0.0,\n",
            "    \"recall\": 0.0,\n",
            "    \"f1-score\": 0.0,\n",
            "    \"support\": 1.0\n",
            "  },\n",
            "  \"accuracy\": 0.6666666666666666,\n",
            "  \"macro avg\": {\n",
            "    \"precision\": 0.3333333333333333,\n",
            "    \"recall\": 0.5,\n",
            "    \"f1-score\": 0.4,\n",
            "    \"support\": 3.0\n",
            "  },\n",
            "  \"weighted avg\": {\n",
            "    \"precision\": 0.4444444444444444,\n",
            "    \"recall\": 0.6666666666666666,\n",
            "    \"f1-score\": 0.5333333333333333,\n",
            "    \"support\": 3.0\n",
            "  }\n",
            "}\n",
            "\n",
            "=== Evaluating ensemble (CTC majority vote) on authors' original validation folders ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authors' Cybersecurity Val:      acc=0.5714, FP=0.0000, FN=0.4286, N=7\n",
            "Authors' Non-cybersecurity Val:  acc=1.0000, FP=0.0000, FN=0.0000, N=9\n",
            "\n",
            "Done ✅ — ready for your screen recording.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05a14886"
      },
      "source": [
        "# Task\n",
        "Explain the error in the selected code, fix it, and adapt the entire Python code to run in Google Colab, including necessary modifications for argument handling and execution flow within a notebook environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "390b58bc",
        "outputId": "d884d8f0-dcc2-4396-b308-4e2bd69c2d2a"
      },
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the directory to save the data\n",
        "save_dir = Path(WORKDIR) / \"data\"\n",
        "save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save vectorized data and labels for train, test, and validation sets\n",
        "joblib.dump(X_train, save_dir / \"X_train_vectorized.joblib\")\n",
        "joblib.dump(X_val, save_dir / \"X_val_vectorized.joblib\")\n",
        "joblib.dump(X_test, save_dir / \"X_test_vectorized.joblib\") # Save test vectorized data\n",
        "joblib.dump(y_train, save_dir / \"y_train_labels.joblib\")\n",
        "joblib.dump(y_val, save_dir / \"y_val_labels.joblib\")\n",
        "joblib.dump(y_test, save_dir / \"y_test_labels.joblib\")   # Save test labels\n",
        "\n",
        "# Save original text data for train, test, and validation sets\n",
        "with open(save_dir / \"X_train_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for text in X_train_text:\n",
        "        f.write(text + \"\\n\")\n",
        "\n",
        "with open(save_dir / \"X_val_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for text in X_val_text:\n",
        "        f.write(text + \"\\n\")\n",
        "\n",
        "with open(save_dir / \"X_test_text.txt\", \"w\", encoding=\"utf-8\") as f: # Save test text data\n",
        "    for text in X_test_text:\n",
        "        f.write(text + \"\\n\")\n",
        "\n",
        "\n",
        "print(f\"Train, test, and validation data saved to {save_dir}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train, test, and validation data saved to work_colab/data\n"
          ]
        }
      ]
    }
  ]
}